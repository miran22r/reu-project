from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction import DictVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn import metrics
from operator import itemgetter
from sklearn.metrics import classification_report
import numpy as np
import csv
import os
import glob
import string
from random import shuffle
import itertools

labels = ['0', '1']
words = []
label_names = []
os.chdir('pos')
file_names = []
files= []

count_vect = CountVectorizer()

for filename in glob.glob('*.txt'):
	file = open(filename, 'r')
	files.append(file.read())
	file_names.append("/pos/" + filename)
	with open(filename) as f:	
		yo = file.readline().split()
		for word in yo: 
			words.append(word.strip(string.punctuation))

pos_dict = []

for x in words:
	if x not in pos_dict:
		pos_dict.append(x)

words = []
os.chdir('../neg')
for filename in glob.glob('*.txt'):
	file = open(filename, 'r')	
	files.append(file.read())
	file_names.append("/neg/" + filename)
	with open(filename) as f:
		yo = file.readline().split()
		for word in yo: 
			words.append(word.strip(string.punctuation))
		files.extend(yo)
neg_dict = []
for x in words:
	if x not in neg_dict:
		neg_dict.append(x)

os.chdir('../')

sparse_matrix = count_vect.fit_transform(files)
tfidf_transformer = TfidfTransformer()
train_tfidf = tfidf_transformer.fit_transform(sparse_matrix)

target = ['pos'] * 1000
target.extend(['neg']*1000)
classifier = MultinomialNB().fit(train_tfidf, target)

test = ['good', 'bad', 'perfect', 'immature', 'hate', 'surprise']
test_counts = count_vect.transform(test)
test_tfidf = tfidf_transformer.transform(test_counts)

predicted = classifier.predict(test_tfidf)
x = 0
for doc, category in zip (test, predicted):
	print ('%r => %s' % (doc, predicted[x]))
	x = x +1

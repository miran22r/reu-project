from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import HashingVectorizer
from sklearn import metrics
from sklearn.linear_model import SGDClassifier
from operator import itemgetter
from sklearn.metrics import classification_report
from sklearn.pipeline import Pipeline
import numpy as np
import csv
import os
import glob
import string
from random import shuffle
import itertools
import nltk 

files= []

count_vect = CountVectorizer()

with open('positive.review', 'r') as f:
	files = f.readlines()

poswords = []
negwords = []

for review in files:
	review = review.translate(None, ':')
	review = review.translate(None, '01234567')
	review = review.split(' ')
	poswords.extend(review)

with open('negative.review', 'r') as f:
	files = f.readlines()

print 'Currently building our vocabulary'

for review in files:
	review = review.translate(None, ':')
	review = review.translate(None, '01234')
	review = review.split(' ')
	negwords.extend(review)

reviews = []
reviews.extend(negwords)
reviews.extend(poswords)

print 'Currently making our matrix'

sparse_matrix = count_vect.fit_transform(reviews)
tfidf_transformer = TfidfTransformer()
train_tfidf = tfidf_transformer.fit_transform(sparse_matrix)

target = ['neg'] * len(negwords)
target.extend(['pos'] * len(poswords))
#classifier = MultinomialNB().fit(train_tfidf, target)
classifier = Pipeline([('vect', CountVectorizer()),
			('tfidf', TfidfTransformer()), 
			('clf', MultinomialNB()),])

print 'Currently testing out test input'

test = ['poor plot', 'amazing action packed edge of my seat cool special effects','cliche, overused, unoriginal', 'perfect, amazing, innovative, nothing like it', 'immature stupid high school vince vaughan', 'hate stupid ugly annoying hate', 'surprise unexpected did not see it coming, twist, off guard']

classifier = classifier.fit(reviews, target)
predicted = classifier.predict(test)
x = 0
for doc, category in zip (test, predicted):
	print ('%r => %s' % (doc, predicted[x]))
	x = x +1

test = []

print 'Currently loading test data'

with open('unlabeled.review', 'r') as f:
	test = f.readlines()

print 'loading training data'

positive = '#label#:positive'
negative = '#label#:negative'
answers = []

for x in test:
	if positive in x:
		answers.append('pos')
	if negative in x:
		answers.append('neg')

test_counts = count_vect.transform(test)
test_tfidf = tfidf_transformer.transform(test_counts)

predicted = classifier.predict(test)

print np.mean(predicted == answers)

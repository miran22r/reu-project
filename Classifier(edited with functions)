from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn import metrics
from sklearn.linear_model import SGDClassifier
from operator import itemgetter
from sklearn.metrics import classification_report
import numpy as np
import csv
import os
import glob
import string
from random import shuffle
import itertools
import nltk 
import sys

class Main:

	fileName1 = ""
	fileName2 = ""
	testFile = ""
	test = []
	files = []
	poswords = []
	negwords = []
	reviews = []
	answers = []
	sentiment1 = ""
	sentiment2 = ""

#fileName1 = positive reviews, fileName2 = negative reviews, test file = unlabeled, sentiment1 is positive, netiment2 is negative
	def check_arguments (argv):
		
		if len(argv) < 5:
			print 'Sorry, but you input the wrong amount of arguments.'
			sys.exit()
		else:
			fileName1 = argv[1]
			fileName2 = argv[2]
			testFile = argv[3]	
			sentiment1 = argv[4]
			sentiment2 = argv[5]

	def load_files(inputFile, vocabulary):
		print 'Currently building our vocabulary'
		with open(inputFile, 'r') as f:
			files = f.readlines()
		for review in files:
			review = review.translate(None, ':')
			review = review.translate(None, '01234567')
			review = review.split(' ')
			vocabulary.extend(review)

	def make_Matrix(data):
		count_vect = CountVectorizer()
		sparse_matrix = count_vect.fit_transform(reviews)
		return sparse_matrix

	def transform(matrix):
		tfidf_transformer = TfidfTransformer()
		train_tfidf = tfidf_transformer.fit_transform(matrix)
		return train_tfidf

	def build_answers(sent1, sent2, dictionary1, dictionary2):
		target = [sent1] * len(dictionary1)
		target.extend([sent2] * len(dictionary2))
		return target

	def load_test(fileName):
		with open(fileName, 'r') as f:
			test = f.readlines()

	def add_answers(sentiment1, sentiment2):
		for x in test:
			if sentiment1 in x:
				answers.append(sentiment1)
			if sentiment2 in x:
				answers.append(sentiment2)

	def classify():
		test_counts = count_vect.transform(test)
		test_tfidf = tfidf_transformer.transform(test_counts)
		predicted = classifier.predict(test_tfidf)
		return predicted

	check_arguments(sys.argv)
	print fileName1
	print fileName2
	load_files(fileName1, poswords)
	load_files(fileName2, negwords)

	reviews.extend(poswords)
	reviews.extend(negwords)

	train_tfidf = transform(make_Matrix(reviews))
	target = build_answers (sentiment1, sentiment2, negwords, poswords)
	classifier = MultinomialNB().fit(train_tfidf, target)

	load_test(testFile)

	add_answers(sentiment1, sentiment2)
	predicted = classify()

	print np.mean(predicted == answers)
